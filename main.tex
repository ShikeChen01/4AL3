\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[]{acl}
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

\usepackage{amsmath}      % math environments
\usepackage{amssymb}      % extra math symbols
\usepackage{amsfonts}     % math fonts, including \mathbb
\usepackage{bbm}          % gives \mathbbm{1} (indicator function)
\usepackage{graphicx}     % images
\usepackage{booktabs}     % pretty tables (optional)
\usepackage{hyperref}     % clickable refs (always useful)


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Group X Progress Report:\\My Group's Project Name}


\author{First Author, Second Author, Third Author \\
  \texttt{\{macid1,macid2,macid3\}@mcmaster.ca} }

%\author{
%  \textbf{First Author\textsuperscript{1}},
%  \textbf{Second Author\textsuperscript{1,2}},
%  \textbf{Third T. Author\textsuperscript{1}},
%  \textbf{Fourth Author\textsuperscript{1}},
%\\
%  \textbf{Fifth Author\textsuperscript{1,2}},
%  \textbf{Sixth Author\textsuperscript{1}},
%  \textbf{Seventh Author\textsuperscript{1}},
%  \textbf{Eighth Author \textsuperscript{1,2,3,4}},
%\\
%  \textbf{Ninth Author\textsuperscript{1}},
%  \textbf{Tenth Author\textsuperscript{1}},
%  \textbf{Eleventh E. Author\textsuperscript{1,2,3,4,5}},
%  \textbf{Twelfth Author\textsuperscript{1}},
%\\
%  \textbf{Thirteenth Author\textsuperscript{3}},
%  \textbf{Fourteenth F. Author\textsuperscript{2,4}},
%  \textbf{Fifteenth Author\textsuperscript{1}},
%  \textbf{Sixteenth Author\textsuperscript{1}},
%\\
%  \textbf{Seventeenth S. Author\textsuperscript{4,5}},
%  \textbf{Eighteenth Author\textsuperscript{3,4}},
%  \textbf{Nineteenth N. Author\textsuperscript{2,5}},
%  \textbf{Twentieth Author\textsuperscript{1}}
%\\
%\\
%  \textsuperscript{1}Affiliation 1,
%  \textsuperscript{2}Affiliation 2,
%  \textsuperscript{3}Affiliation 3,
%  \textsuperscript{4}Affiliation 4,
%  \textsuperscript{5}Affiliation 5
%\\
%  \small{
%    \textbf{Correspondence:} \href{mailto:email@domain}{email@domain}
%  }
%}

\begin{document}
\maketitle
% \begin{abstract}
% \end{abstract}

\section{Introduction}
Currently majority of the financial market prediction models are relying 
on traditional index digging, technical analysis, regression models. 
However, with modern machine learning techniques emerging in NLP, 
the industry see a huge potential in bringing complex models to 
analyze and predict the market movement. 

Over the years, majority of the investors, including professionals, 
have struggled to consistently beat the S\&P500 index. In this challenge, 
we also understand the effect of the efficient market hypothesis, which 
states that stock prices fully reflect all available information. Thus, it is impossible to 
consistently achieve higher returns than average market returns on a
risk-adjusted basis, given that stock prices should only react to new information. 

However, with the advancement of machine learning techniques, if we are able 
to implement these new techniques to analyze the market data, we may be able to uncover
hidden patterns and profit. Since these are also considered as new information, the 
effective market hypothesis still holds. 

Since we do not know the preprocessing steps of the features, it is difficult for the 
team to use traditional, statistical methods to give meaningful insightful analysis. Thus, 
we decided to use predominantly unsuperised learning methods to analyze the data and
predict the S\&P500 return.

The overall objective of our project is to predict the S\&P500 return 
using the pre-processed data provided by Hull Tactical. 

\section{Related Work}

Here, talk about the related work you encountered for your approach. Cite at least 5 references. Refer to item 2. No one has done exactly your task? Write about the most similar thing you can find. This should be around 0.25-0.5 pages.


What is a good approach to predict stock prices with unsuprivised machine learning techniques?
Instinctively, reinforcement learning especially Proximal Policy Optimization (PPO)
seems to be the best fit for this task.[1]
PPO is an on-policy actor-critic method that maximizes a clipped surrogate objective 
to prevent destabilizing policy updates. In markets, this is attractive because 
the reward feedback comes from interaction (PnL, risk-adjusted returns), not 
labeled targets—i.e., the problem is effectively label-free. Second, the environment is 
non-stationary and noisy, so conservative trust-region-like updates (PPO’s clipping) 
curb policy collapse. At last, PPO pairs naturally with recurrent encoders (e.g., GRU) 
and risk-aware rewards (e.g., Sortino ratio) already shown effective in GDQN/GDPG-style systems.[2]

How do we measure risk-adjusted returns? The most common way is to use the Sharpe ratio. The 
Sharpe ratio is a good indicator for most of the investment strategies. However, in the case of 
reinforcement learning based trading strategy, it is not enough. The biggest risk of such trading
strategy is the non-deterministic nature of a neural netowrk. Thus, careful selection of a neural
network architecture is important to reduce the variance of the returns.



\section{Dataset}

The dataset used in this project is the same equity return prediction dataset  
referenced in the project proposal. An updated version of the dataset was  
released on November 6th. The update primarily expanded the number of  
observations and refined the calculation of forward returns. However, this  
revision did not materially change the statistical properties of the data  
distribution, nor did it require changes to our modeling pipeline, since our  
learning framework does not rely on absolute scale but rather on relative  
directional signals.

Each row in the dataset corresponds to a single market snapshot at time $t$ for  
a specific equity, containing both price-derived technical indicators and  
macroeconomic or market-level descriptors. The prediction target is  
\texttt{forward\_returns}, the realized percentage change in the security price  
from $t$ to $t + \Delta$, where $\Delta$ is defined by the dataset provider.  
In our processing, we rename this column to \texttt{target} for consistency.

As expected in financial forecasting problems, the empirical distribution of  
\texttt{target} is highly concentrated around zero, with heavy tails and high  
kurtosis. This reflects the structural difficulty of short-horizon return  
prediction, where most price movements are dominated by noise.

The dataset also contains missing values, particularly in indicators  
constructed from rolling windows of different lengths. To avoid discarding  
information, we do not remove rows with missing data. Instead, we replace  
\texttt{NaN} values with zeros and add binary missing indicator flags for each  
affected feature:
\[
x^{(\text{filled})}_i =
\begin{cases}
0, & \text{if } x_i \text{ was missing} \\
x_i, & \text{otherwise}
\end{cases}
\]
This preserves potential information carried by the absence of values. Data  
loading and cleaning follows our \texttt{load\_data} and missing-indicator  
augmentation utility functions.

\vspace{6pt}
\section{Features}

We work directly with the numerical feature columns provided in the dataset.  
No manual feature engineering was performed beyond:
\begin{itemize}
    \item Standardization of all numeric features via $z$-score normalization.
    \item Addition of missing-value indicator features for all originally
          \texttt{NaN}-carrying columns.
    \item Optional inclusion of a constant bias term during reinforcement
          learning.
\end{itemize}

Because financial features often exhibit collinearity, we conducted correlation  
inspections to assess which features carry directional information relative to  
\texttt{target}. Point-biserial and Pearson correlations were used for this  
purpose. In the reinforcement learning setting, the environment returns a state  
vector consisting of the normalized feature vector at time step $t$, optionally  
concatenated with the agent's previous action to preserve position memory.

\vspace{6pt}
\section{Implementation}

Our core modeling framework is a reinforcement learning (RL) agent based on  
Proximal Policy Optimization (PPO). Rather than predicting raw return values,  
the task is formulated as a sequential decision problem. At each timestep, the  
agent selects one of three discrete actions:
\[
a_t \in \{-1, 0, +1\}
\]
representing \texttt{sell}, \texttt{hold}, or \texttt{buy} decisions.

\subsection{Environment}

We define a custom environment that sequentially feeds feature vectors over  
time. The reward reflects directional correctness rather than magnitude:
\[
r_t = \mathbb{1}(\text{sign}(a_t) = \text{sign}(\text{target}_t)) -
      \mathbb{1}(\text{sign}(a_t) \neq \text{sign}(\text{target}_t))
\]
This converts return prediction into directional prediction, which is more  
robust for noisy financial data.

\subsection{Policy and Value Networks}

The agent maintains:
\begin{itemize}
    \item A policy network $\pi_\theta(a_t | s_t)$ producing action probabilities.
    \item A value network $V_\phi(s_t)$ estimating expected cumulative reward.
\end{itemize}

Both networks are multilayer perceptrons with ReLU activations. The policy is  
trained using the PPO clipped surrogate objective:
\[
L_{\pi} = -\mathbb{E}\left[\min(r_t(\theta)\hat{A}_t,
\text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_t)\right]
\]
The value network is trained via mean-squared error against return-to-go.

\subsection{Training Procedure}

Training alternates between:
\begin{enumerate}
    \item Rollout: interact with the environment to collect trajectories.
    \item Update: compute generalized advantage estimates (GAE) and apply PPO.
\end{enumerate}

Although GPU acceleration is used for neural network forward and backward  
passes, rollout occurs step-by-step in Python. This creates a performance  
bottleneck where environment interaction becomes the dominant runtime cost.  
Parallel rollout environments are a planned optimization.

\subsection{Baselines}

To benchmark reinforcement learning performance, we also train three  
supervised models:
\begin{itemize}
    \item Gradient-Boosted Trees.
    \item Multilayer Perceptron Regression (MSE objective).
\end{itemize}

These baselines help evaluate whether reward-based directional optimization  
provides an advantage over direct regression on \texttt{target}.

\section{Results and Evaluation}

How are you evaluating your model? What results do you have so far? What are your baselines? Refer to item 5. This may take around 0.5 pages.

\section{Feedback and Plans}

Write about your plans for the remainder of the project. This should include a discussion of the feedback you received from your TA, and how you plan to improve your approach. Reflect on your implementation and areas for improvement. Refer to item 6. This may be around 0.5 pages.

\section{Template Notes}

You can remove this section or comment it out, as it only contains instructions for how to use this template. You may use subsections in your document as you find appropriate.

\subsection{Tables and figures}

See Table~\ref{citation-guide} for an example of a table and its caption.
See Figure~\ref{fig:experiments} for an example of a figure and its caption.


\begin{figure}[t]
  \includegraphics[width=\columnwidth]{example-image-golden}
  \caption{A figure with a caption that runs for more than one line.
    Example image is usually available through the \texttt{mwe} package
    without even mentioning it in the preamble.}
  \label{fig:experiments}
\end{figure}

\begin{figure*}[t]
  \includegraphics[width=0.48\linewidth]{example-image-a} \hfill
  \includegraphics[width=0.48\linewidth]{example-image-b}
  \caption {A minimal working example to demonstrate how to place
    two images side-by-side.}
\end{figure*}


\subsection{Citations}

\begin{table*}
  \centering
  \begin{tabular}{lll}
    \hline
    \textbf{Output}           & \textbf{natbib command} & \textbf{ACL only command} \\
    \hline
    \citep{Gusfield:97}       & \verb|\citep|           &                           \\
    \citealp{Gusfield:97}     & \verb|\citealp|         &                           \\
    \citet{Gusfield:97}       & \verb|\citet|           &                           \\
    \citeyearpar{Gusfield:97} & \verb|\citeyearpar|     &                           \\
    \citeposs{Gusfield:97}    &                         & \verb|\citeposs|          \\
    \hline
  \end{tabular}
  \caption{\label{citation-guide}
    Citation commands supported by the style file.
  }
\end{table*}

Table~\ref{citation-guide} shows the syntax supported by the style files.
We encourage you to use the natbib styles.
You can use the command \verb|\citet| (cite in text) to get ``author (year)'' citations, like this citation to a paper by \citet{Gusfield:97}.
You can use the command \verb|\citep| (cite in parentheses) to get ``(author, year)'' citations \citep{Gusfield:97}.
You can use the command \verb|\citealp| (alternative cite without parentheses) to get ``author, year'' citations, which is useful for using citations within parentheses (e.g. \citealp{Gusfield:97}).

\subsection{References}

\nocite{Ando2005,andrew2007scalable,rasooli-tetrault-2015}

Many websites where you can find academic papers also allow you to export a bib file for citation or bib formatted entry. Copy this into the \texttt{custom.bib} and you will be able to cite the paper in the \LaTeX{}. You can remove the example entries.

\subsection{Equations}

An example equation is shown below:
\begin{equation}
  \label{eq:example}
  A = \pi r^2
\end{equation}

Labels for equation numbers, sections, subsections, figures and tables
are all defined with the \verb|\label{label}| command and cross references
to them are made with the \verb|\ref{label}| command.
This an example cross-reference to Equation~\ref{eq:example}. You can also write equations inline, like this: $A=\pi r^2$.


% \section*{Limitations}

\section*{Team Contributions}

Write in this section a few sentences describing the contributions of each team member. What did each member work on? Refer to item 7.

% Bibliography entries for the entire Anthology, followed by custom entries
%\bibliography{custom,anthology-overleaf-1,anthology-overleaf-2}

% Custom bibliography entries only
\bibliography{custom}

% \appendix

% \section{Example Appendix}
% \label{sec:appendix}

% This is an appendix.

\end{document}
